{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6f2aff62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total interactions: 599635\n",
      "Incomplete sessions (null duration): 325388\n",
      "Percentage incomplete: 54.26%\n",
      "Missing interaction_ids: []\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the raw data\n",
    "df = pd.read_csv('../data/raw/lsapp.tsv', sep='\\t')\n",
    "\n",
    "# Create interaction_id and session_id columns using the logic from your provided code\n",
    "df['timestamp'] = pd.to_datetime(df['timestamp'])\n",
    "\n",
    "df['interaction_id'] = (\n",
    "    ((df.timestamp - df.timestamp.shift(1) > pd.Timedelta(1, 'm')) & (df.event_type == 'Opened'))\n",
    "    | ~(df.app_name == df.app_name.shift(1))\n",
    "    | ~(df.user_id == df.user_id.shift(1))\n",
    ").cumsum()\n",
    "\n",
    "df['session_id'] = (\n",
    "    ((df.timestamp - df.timestamp.shift(1) > pd.Timedelta(5, 'm')) & (df.event_type == 'Opened'))\n",
    "    | ~(df.user_id == df.user_id.shift(1))\n",
    ").cumsum()\n",
    "\n",
    "# Get ALL unique interaction_ids that exist in the data\n",
    "all_interaction_ids = df['interaction_id'].unique()\n",
    "\n",
    "# For each interaction, get the open and close times\n",
    "df_start = df[df['event_type'] == 'Opened'].drop_duplicates(subset=['interaction_id'], keep='first')\n",
    "df_end = df[df['event_type'] == 'Closed'].drop_duplicates(subset=['interaction_id'], keep='last')\n",
    "\n",
    "# Create a complete DataFrame with ALL interaction_ids\n",
    "df_complete = pd.DataFrame({'interaction_id': all_interaction_ids})\n",
    "\n",
    "# Merge with start events (Opened)\n",
    "df_start = df_start.set_index('interaction_id')\n",
    "df_complete = df_complete.set_index('interaction_id')\n",
    "df_complete = df_complete.join(df_start, how='left')\n",
    "\n",
    "# Merge with end events (Closed)\n",
    "df_end = df_end.set_index('interaction_id')\n",
    "df_complete['close_time'] = df_end['timestamp']\n",
    "\n",
    "# Duration in minutes - will be NaN for incomplete sessions\n",
    "df_complete['duration'] = (df_complete['close_time'] - df_complete['timestamp']).dt.total_seconds() / 60.0\n",
    "\n",
    "# Reset index to get interaction_id as a column\n",
    "df_clean = df_complete.reset_index()\n",
    "\n",
    "# Rename columns for clarity\n",
    "df_clean = df_clean.rename(columns={'timestamp': 'open_time'})\n",
    "\n",
    "# Add required columns\n",
    "\n",
    "# is_weekend\n",
    "df_clean['is_weekend'] = df_clean['open_time'].dt.weekday >= 5\n",
    "\n",
    "# time_since_last_app (in minutes)\n",
    "df_clean = df_clean.sort_values(['user_id', 'session_id', 'open_time'])\n",
    "df_clean['time_since_last_app'] = df_clean.groupby(['user_id', 'session_id'])['open_time'].diff().dt.total_seconds() / 60.0\n",
    "\n",
    "# hour_of_day\n",
    "df_clean['hour_of_day'] = df_clean['open_time'].dt.hour\n",
    "\n",
    "# time_since_session_start (in minutes)\n",
    "df_clean['session_start_time'] = df_clean.groupby(['user_id', 'session_id'])['open_time'].transform('min')\n",
    "df_clean['time_since_session_start'] = (df_clean['open_time'] - df_clean['session_start_time']).dt.total_seconds() / 60.0\n",
    "df_clean = df_clean.drop(columns=['session_start_time'])\n",
    "\n",
    "# day_0 ... day_6 (one-hot for day of week, where Monday=0)\n",
    "for i in range(7):\n",
    "    df_clean[f'day_{i}'] = (df_clean['open_time'].dt.weekday == i)\n",
    "\n",
    "# Drop event_type and any columns not needed\n",
    "columns_to_keep = [\n",
    "    'user_id', 'session_id', 'interaction_id', 'app_name', 'open_time', 'duration',\n",
    "    'is_weekend', 'time_since_last_app', 'hour_of_day', 'time_since_session_start'\n",
    "]\n",
    "# columns_to_keep = [\n",
    "#     'user_id', 'session_id', 'interaction_id', 'app_name', 'open_time', 'duration',\n",
    "#     'is_weekend', 'time_since_last_app', 'hour_of_day', 'time_since_session_start',\n",
    "#     'day_0', 'day_1', 'day_2', 'day_3', 'day_4', 'day_5', 'day_6'\n",
    "# ]\n",
    "df_clean = df_clean[columns_to_keep]\n",
    "\n",
    "# Save cleaned data\n",
    "df_clean.to_csv('../data/cleaned/LSAPP_Processed.csv', index=False)\n",
    "\n",
    "# Print summary of incomplete sessions\n",
    "incomplete_count = df_clean['duration'].isna().sum()\n",
    "total_count = len(df_clean)\n",
    "print(f\"Total interactions: {total_count}\")\n",
    "print(f\"Incomplete sessions (null duration): {incomplete_count}\")\n",
    "print(f\"Percentage incomplete: {incomplete_count/total_count:.2%}\")\n",
    "\n",
    "# Check for missing interaction_ids\n",
    "expected_ids = set(range(1, df['interaction_id'].max() + 1))\n",
    "actual_ids = set(df_clean['interaction_id'].dropna())\n",
    "missing_ids = expected_ids - actual_ids\n",
    "print(f\"Missing interaction_ids: {sorted(missing_ids)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cosmos",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
